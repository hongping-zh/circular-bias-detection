{
  "title": "Algorithm Benchmark Suite v2.0: Synthetic Dataset for Circular Bias Detection",
  "description": "<h1>Algorithm Benchmark Suite v2.0</h1>\n\n<p>A comprehensive benchmark dataset for evaluating circular bias detection algorithms in AI evaluation contexts.</p>\n\n<h2>Dataset Contents</h2>\n\n<p>This archive contains <strong>10 CSV files</strong> with synthetic evaluation data across diverse scenarios:</p>\n\n<ul>\n<li><strong>algorithm_benchmark_suite.csv</strong> - Main benchmark (20 records, 7 fields)</li>\n<li><strong>scenario_*.csv</strong> (9 files) - Controlled experiments with varying:\n<ul>\n<li>Noise levels (0.05-0.2)</li>\n<li>Bias intensities (0.0-0.9)</li>\n<li>Temporal configurations (8-20 periods)</li>\n<li>Algorithm counts (3-6 algorithms)</li>\n</ul>\n</li>\n</ul>\n\n<h2>Data Schema</h2>\n\n<p>Each record includes standardized fields:</p>\n<ul>\n<li><code>time_period</code>: Evaluation period ID (integer)</li>\n<li><code>algorithm</code>: Algorithm identifier (string)</li>\n<li><code>performance</code>: Performance metric [0-1] (float)</li>\n<li><code>constraint_compute</code>: Computational constraint (float)</li>\n<li><code>constraint_memory</code>: Memory constraint in GB (float)</li>\n<li><code>constraint_dataset_size</code>: Training dataset size (integer)</li>\n<li><code>evaluation_protocol</code>: Protocol version (string)</li>\n</ul>\n\n<h2>Use Cases</h2>\n<ul>\n<li>Benchmarking bias detection algorithms</li>\n<li>Testing evaluation methodology robustness</li>\n<li>Research on algorithmic fairness in temporal domains</li>\n<li>Validation of circular reasoning detection frameworks</li>\n</ul>\n\n<h2>Reproducibility</h2>\n\n<p>All data is fully reproducible using the included generation script:<br>\n<code>python data/generate_benchmark_data.py --validate</code></p>\n\n<h2>Associated Software</h2>\n\n<p>Framework implementation: <a href=\"https://github.com/hongping-zh/circular-bias-detection\">https://github.com/hongping-zh/circular-bias-detection</a></p>\n\n<h2>Documentation</h2>\n<ul>\n<li><strong>Data Dictionary</strong>: Comprehensive field specifications</li>\n<li><strong>JSON Schema</strong>: Formal validation rules</li>\n<li><strong>README</strong>: Usage examples and guidelines</li>\n<li><strong>CHANGELOG</strong>: Version history and updates</li>\n</ul>\n\n<h2>Citation</h2>\n<pre>Zhang, H. (2024). Algorithm Benchmark Suite v2.0 [Data set]. Zenodo. https://doi.org/10.5281/zenodo.17196639</pre>",
  
  "creators": [
    {
      "name": "Zhang, Hongping",
      "affiliation": "Independent Researcher",
      "orcid": "0009-0000-2529-4613"
    }
  ],
  
  "keywords": [
    "algorithm evaluation",
    "bias detection",
    "benchmark dataset",
    "machine learning fairness",
    "circular reasoning",
    "temporal bias",
    "AI evaluation",
    "synthetic data",
    "reproducible research",
    "open science",
    "evaluation methodology",
    "statistical testing",
    "performance metrics",
    "constraint analysis"
  ],
  
  "license": "CC-BY-4.0",
  
  "upload_type": "dataset",
  
  "access_right": "open",
  
  "related_identifiers": [
    {
      "identifier": "https://github.com/hongping-zh/circular-bias-detection",
      "relation": "isSupplementTo",
      "scheme": "url",
      "resource_type": "software"
    },
    {
      "identifier": "https://github.com/hongping-zh/circular-bias-detection/blob/main/data/README.md",
      "relation": "isDocumentedBy",
      "scheme": "url",
      "resource_type": "publication-technicalnote"
    }
  ],
  
  "subjects": [
    {
      "term": "Machine Learning",
      "scheme": "keyword"
    },
    {
      "term": "Algorithmic Fairness",
      "scheme": "keyword"
    },
    {
      "term": "Bias Detection",
      "scheme": "keyword"
    },
    {
      "term": "Evaluation Methodology",
      "scheme": "keyword"
    }
  ],
  
  "version": "2.0.0",
  
  "language": "eng",
  
  "notes": "This dataset supports research on detecting circular reasoning bias in algorithm evaluation. All data is synthetically generated with controlled bias and noise parameters for reproducible benchmarking. Complete generation code and validation schema included.",
  
  "references": [
    "Zhang, H. (2024). A Comprehensive Statistical Framework for Detecting Circular Reasoning Bias in AI Algorithm Evaluation. Submitted to Journal of the American Statistical Association."
  ]
}
