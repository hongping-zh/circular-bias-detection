"""One-sentence risk summary generation for non-expert users.

Converts complex statistical results into plain language risk assessments.
"""
from typing import Dict, Optional, List
import numpy as np


def generate_risk_summary(
    detection_result: Dict,
    metric_name: str = "performance",
    include_recommendations: bool = True
) -> str:
    """Generate a one-sentence risk summary from detection results.
    
    Parameters:
    -----------
    detection_result : dict
        Result dictionary from detect_bias() or other detection functions
    metric_name : str, default="performance"
        Name of the metric being evaluated (for clarity)
    include_recommendations : bool, default=True
        Whether to include actionable recommendations
    
    Returns:
    --------
    str
        Plain language risk summary
    
    Examples:
    ---------
    >>> result = detect_bias(model, X, y, accuracy_score)
    >>> summary = generate_risk_summary(result, "accuracy")
    >>> print(summary)
    "é«˜é£é™©ï¼šæ€§èƒ½éšè®¡ç®—èµ„æºçº¿æ€§å¢é•¿ï¼ˆÏ_PC=0.78ï¼‰ï¼Œå¯èƒ½å­˜åœ¨è°ƒå‚ä½œå¼Š"
    """
    p_value = detection_result.get('p_value', 1.0)
    alpha = detection_result.get('alpha', 0.05)
    observed = detection_result.get('observed_metric', 0.0)
    
    # Determine risk level
    if p_value <= 0.001:
        risk_level = "æé«˜é£é™©"
        risk_emoji = "ğŸš¨"
    elif p_value <= 0.01:
        risk_level = "é«˜é£é™©"
        risk_emoji = "âš ï¸"
    elif p_value <= alpha:
        risk_level = "ä¸­ç­‰é£é™©"
        risk_emoji = "âš¡"
    elif p_value <= 0.1:
        risk_level = "ä½é£é™©"
        risk_emoji = "â„¹ï¸"
    else:
        risk_level = "æ— æ˜æ˜¾é£é™©"
        risk_emoji = "âœ…"
    
    # Build summary components
    components = []
    
    # Main risk statement
    if p_value <= alpha:
        components.append(
            f"{risk_emoji} {risk_level}ï¼š{metric_name}å¼‚å¸¸é«˜ "
            f"(è§‚æµ‹å€¼={observed:.3f}, p={p_value:.4f})"
        )
    else:
        components.append(
            f"{risk_emoji} {risk_level}ï¼š{metric_name}åœ¨æ­£å¸¸èŒƒå›´å†… "
            f"(p={p_value:.3f} > {alpha})"
        )
    
    # Add specific patterns if available
    patterns = []
    
    # Check for correlation patterns (from PSI analysis)
    if 'psi_correlation' in detection_result:
        corr = detection_result['psi_correlation']
        if abs(corr) > 0.7:
            pattern_type = "çº¿æ€§å¢é•¿" if corr > 0 else "çº¿æ€§ä¸‹é™"
            patterns.append(f"æ€§èƒ½éšè®¡ç®—èµ„æº{pattern_type}ï¼ˆÏ_PC={corr:.2f}ï¼‰")
    
    # Check for stratification (imbalanced data handling)
    if detection_result.get('stratified', False):
        patterns.append("å·²è€ƒè™‘ç±»åˆ«ä¸å¹³è¡¡")
    
    # Check for parallel execution
    if detection_result.get('n_jobs', 1) > 1:
        patterns.append(f"ä½¿ç”¨{detection_result['n_jobs']}æ ¸å¹¶è¡ŒéªŒè¯")
    
    # Check for retrain method (conservative)
    if detection_result.get('null_method') == 'retrain':
        patterns.append("ä½¿ç”¨ä¿å®ˆé‡è®­ç»ƒæ£€éªŒ")
    
    if patterns:
        components.append("ï¼Œ".join(patterns))
    
    # Add potential cheating type
    if p_value <= alpha:
        cheating_types = []
        
        if abs(detection_result.get('psi_correlation', 0)) > 0.7:
            cheating_types.append("è°ƒå‚ä½œå¼Š")
        
        if detection_result.get('n_classes', 2) == 2 and observed > 0.95:
            cheating_types.append("æ•°æ®æ³„éœ²")
        
        if detection_result.get('subsampled', False):
            cheating_types.append("æ ·æœ¬é€‰æ‹©åå·®")
        
        if cheating_types:
            components.append(f"å¯èƒ½å­˜åœ¨{' æˆ– '.join(cheating_types)}")
    
    # Add recommendations
    if include_recommendations and p_value <= alpha:
        recommendations = _generate_recommendations(detection_result)
        if recommendations:
            components.append(f"å»ºè®®ï¼š{recommendations}")
    
    return "ï¼Œ".join(components)


def generate_batch_risk_summary(
    results: List[Dict],
    test_names: Optional[List[str]] = None,
    correction_applied: bool = False
) -> str:
    """Generate summary for multiple tests.
    
    Parameters:
    -----------
    results : list of dict
        List of detection results
    test_names : list of str, optional
        Names for each test
    correction_applied : bool, default=False
        Whether multiple testing correction was applied
    
    Returns:
    --------
    str
        Batch summary
    
    Examples:
    ---------
    >>> results = [detect_bias(...) for _ in range(5)]
    >>> summary = generate_batch_risk_summary(results)
    >>> print(summary)
    "æ‰¹é‡æ£€æµ‹ï¼š5ä¸ªæµ‹è¯•ä¸­3ä¸ªæ˜¾ç¤ºå¼‚å¸¸ï¼ˆ60%ï¼‰ï¼Œå»ºè®®è¿›ä¸€æ­¥å®¡æŸ¥"
    """
    n_tests = len(results)
    if n_tests == 0:
        return "æ— æµ‹è¯•ç»“æœ"
    
    # Count significant results
    n_significant = sum(1 for r in results if r.get('p_value', 1.0) <= r.get('alpha', 0.05))
    
    # Count by risk level
    high_risk = sum(1 for r in results if r.get('p_value', 1.0) <= 0.01)
    medium_risk = sum(1 for r in results if 0.01 < r.get('p_value', 1.0) <= 0.05)
    
    # Build summary
    components = []
    
    # Main statement
    if correction_applied:
        components.append(f"ğŸ” æ‰¹é‡æ£€æµ‹ï¼ˆå·²æ ¡æ­£å¤šé‡æ¯”è¾ƒï¼‰ï¼š")
    else:
        components.append(f"ğŸ” æ‰¹é‡æ£€æµ‹ï¼š")
    
    components.append(
        f"{n_tests}ä¸ªæµ‹è¯•ä¸­{n_significant}ä¸ªæ˜¾ç¤ºå¼‚å¸¸"
        f"ï¼ˆ{n_significant/n_tests*100:.0f}%ï¼‰"
    )
    
    # Risk breakdown
    if high_risk > 0:
        components.append(f"å…¶ä¸­{high_risk}ä¸ªé«˜é£é™©")
    if medium_risk > 0:
        components.append(f"{medium_risk}ä¸ªä¸­ç­‰é£é™©")
    
    # Overall assessment
    if n_significant == 0:
        components.append("âœ… æ•´ä½“é£é™©ä½")
    elif n_significant <= n_tests * 0.2:
        components.append("âš¡ éƒ¨åˆ†æµ‹è¯•å¼‚å¸¸ï¼Œå»ºè®®é‡ç‚¹å®¡æŸ¥")
    elif n_significant <= n_tests * 0.5:
        components.append("âš ï¸ å¤šä¸ªæµ‹è¯•å¼‚å¸¸ï¼Œå»ºè®®å…¨é¢å®¡æŸ¥")
    else:
        components.append("ğŸš¨ å¤§é‡æµ‹è¯•å¼‚å¸¸ï¼Œå¼ºçƒˆå»ºè®®æ·±å…¥è°ƒæŸ¥")
    
    # List problematic tests
    if test_names and n_significant > 0 and n_significant <= 5:
        problematic = [
            test_names[i] for i, r in enumerate(results)
            if r.get('p_value', 1.0) <= r.get('alpha', 0.05)
        ]
        components.append(f"å¼‚å¸¸æµ‹è¯•ï¼š{', '.join(problematic)}")
    
    return "ï¼Œ".join(components)


def generate_prompt_risk_summary(prompt_analysis_result: Dict) -> str:
    """Generate risk summary for prompt constraint analysis.
    
    Parameters:
    -----------
    prompt_analysis_result : dict
        Result from detect_prompt_constraint_cheating()
    
    Returns:
    --------
    str
        Plain language summary
    
    Examples:
    ---------
    >>> result = detect_prompt_constraint_cheating(prompts, scores)
    >>> summary = generate_prompt_risk_summary(result)
    >>> print(summary)
    "âš ï¸ ä¸­ç­‰é£é™©ï¼š3ç»„æç¤ºè¯é«˜åº¦ç›¸ä¼¼ä½†æ€§èƒ½å·®å¼‚å¤§ï¼Œå¯èƒ½å­˜åœ¨æç¤ºè¯å·¥ç¨‹ä½œå¼Š"
    """
    risk_level = prompt_analysis_result.get('risk_level', 'Unknown')
    n_suspicious = prompt_analysis_result.get('n_suspicious_pairs', 0)
    avg_sim = prompt_analysis_result.get('avg_similarity', 0)
    perf_var = prompt_analysis_result.get('performance_variance', 0)
    
    # Risk emoji
    risk_emoji = {
        'Low': 'âœ…',
        'Medium': 'âš¡',
        'High': 'ğŸš¨'
    }.get(risk_level, 'â„¹ï¸')
    
    # Build summary
    if risk_level == 'Low':
        return (
            f"{risk_emoji} ä½é£é™©ï¼šæç¤ºè¯å¤šæ ·æ€§æ­£å¸¸"
            f"ï¼ˆå¹³å‡ç›¸ä¼¼åº¦={avg_sim:.2f}ï¼‰ï¼Œæœªå‘ç°å¼‚å¸¸æ¨¡å¼"
        )
    elif risk_level == 'Medium':
        return (
            f"{risk_emoji} ä¸­ç­‰é£é™©ï¼š{n_suspicious}ç»„æç¤ºè¯é«˜åº¦ç›¸ä¼¼ä½†æ€§èƒ½å·®å¼‚å¤§"
            f"ï¼ˆç›¸ä¼¼åº¦>{prompt_analysis_result['thresholds']['similarity_threshold']}ï¼‰ï¼Œ"
            f"å¯èƒ½å­˜åœ¨æç¤ºè¯å·¥ç¨‹ä½œå¼Š"
        )
    else:  # High
        return (
            f"{risk_emoji} é«˜é£é™©ï¼šå¤§é‡æç¤ºè¯å¼‚å¸¸ç›¸ä¼¼ä½†æ€§èƒ½æ³¢åŠ¨"
            f"ï¼ˆ{n_suspicious}ç»„å¯ç–‘é…å¯¹ï¼‰ï¼Œ"
            f"å¼ºçƒˆæ€€ç–‘é€šè¿‡æç¤ºè¯å¾®è°ƒæ¥æ“çºµè¯„æµ‹ç»“æœ"
        )


def generate_multivariate_risk_summary(
    multivariate_result: Dict,
    metric_names: Optional[List[str]] = None
) -> str:
    """Generate risk summary for multivariate detection.
    
    Parameters:
    -----------
    multivariate_result : dict
        Result from multivariate PSI or MANOVA
    metric_names : list of str, optional
        Names of metrics being tested
    
    Returns:
    --------
    str
        Plain language summary
    
    Examples:
    ---------
    >>> result = detect_multivariate_bias(...)
    >>> summary = generate_multivariate_risk_summary(result, ['accuracy', 'F1', 'precision'])
    >>> print(summary)
    "ğŸš¨ é«˜é£é™©ï¼š3ä¸ªæŒ‡æ ‡è”åˆæ˜¾ç¤ºå¼‚å¸¸ï¼ˆp=0.002ï¼‰ï¼Œå¤šç»´åº¦ä½œå¼Šæ¨¡å¼"
    """
    p_value = multivariate_result.get('p_value', 1.0)
    alpha = multivariate_result.get('alpha', 0.05)
    n_metrics = multivariate_result.get('n_metrics', 0)
    test_type = multivariate_result.get('test_type', 'unknown')
    
    # Risk level
    if p_value <= 0.001:
        risk_emoji = "ğŸš¨"
        risk_level = "æé«˜é£é™©"
    elif p_value <= 0.01:
        risk_emoji = "âš ï¸"
        risk_level = "é«˜é£é™©"
    elif p_value <= alpha:
        risk_emoji = "âš¡"
        risk_level = "ä¸­ç­‰é£é™©"
    else:
        risk_emoji = "âœ…"
        risk_level = "ä½é£é™©"
    
    # Build summary
    if p_value <= alpha:
        metric_str = f"{n_metrics}ä¸ªæŒ‡æ ‡" if n_metrics > 1 else "æŒ‡æ ‡"
        if metric_names:
            metric_str = f"{', '.join(metric_names[:3])}" + ("ç­‰" if len(metric_names) > 3 else "")
        
        return (
            f"{risk_emoji} {risk_level}ï¼š{metric_str}è”åˆæ˜¾ç¤ºå¼‚å¸¸"
            f"ï¼ˆ{test_type}, p={p_value:.4f}ï¼‰ï¼Œ"
            f"å¤šç»´åº¦ä½œå¼Šæ¨¡å¼ï¼Œå»ºè®®å…¨é¢å®¡æŸ¥"
        )
    else:
        return (
            f"{risk_emoji} {risk_level}ï¼š{n_metrics}ä¸ªæŒ‡æ ‡è”åˆæ£€æµ‹æœªå‘ç°å¼‚å¸¸"
            f"ï¼ˆp={p_value:.3f}ï¼‰"
        )


def _generate_recommendations(detection_result: Dict) -> str:
    """Generate actionable recommendations based on detection results."""
    recommendations = []
    
    p_value = detection_result.get('p_value', 1.0)
    
    # Very strong evidence
    if p_value <= 0.001:
        recommendations.append("ç«‹å³æš‚åœä½¿ç”¨è¯¥æ¨¡å‹")
        recommendations.append("è¿›è¡Œå®Œæ•´çš„æ•°æ®å®¡è®¡")
    
    # Strong evidence
    elif p_value <= 0.01:
        recommendations.append("æ·±å…¥è°ƒæŸ¥è®­ç»ƒæ•°æ®æ¥æº")
        recommendations.append("æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ•°æ®æ³„éœ²")
    
    # Moderate evidence
    elif p_value <= 0.05:
        recommendations.append("åœ¨ç‹¬ç«‹æ•°æ®é›†ä¸Šé‡æ–°éªŒè¯")
        recommendations.append("æ£€æŸ¥è¯„æµ‹æµç¨‹æ˜¯å¦è§„èŒƒ")
    
    # Check specific patterns
    if abs(detection_result.get('psi_correlation', 0)) > 0.7:
        recommendations.append("å®¡æŸ¥è¶…å‚æ•°è°ƒä¼˜è¿‡ç¨‹")
    
    if detection_result.get('n_classes', 2) == 2 and detection_result.get('observed_metric', 0) > 0.95:
        recommendations.append("æ£€æŸ¥æµ‹è¯•é›†æ˜¯å¦æ³„éœ²åˆ°è®­ç»ƒé›†")
    
    return "ï¼›".join(recommendations[:3])  # Limit to top 3


def format_technical_details(detection_result: Dict, verbose: bool = False) -> str:
    """Format technical details for expert users.
    
    Parameters:
    -----------
    detection_result : dict
        Detection result dictionary
    verbose : bool, default=False
        Include all technical details
    
    Returns:
    --------
    str
        Formatted technical summary
    """
    lines = []
    
    # Core statistics
    lines.append("ğŸ“Š æŠ€æœ¯ç»†èŠ‚ï¼š")
    lines.append(f"  è§‚æµ‹æŒ‡æ ‡: {detection_result.get('observed_metric', 0):.4f}")
    lines.append(f"  på€¼: {detection_result.get('p_value', 1.0):.6f}")
    lines.append(f"  æ˜¾è‘—æ€§æ°´å¹³: {detection_result.get('alpha', 0.05)}")
    lines.append(f"  ç½®æ¢æ¬¡æ•°: {detection_result.get('n_permutations', 0)}")
    
    # Confidence interval if available
    if 'p_value_ci' in detection_result:
        ci = detection_result['p_value_ci']
        lines.append(f"  på€¼ç½®ä¿¡åŒºé—´: [{ci[0]:.4f}, {ci[1]:.4f}]")
    
    # Method details
    lines.append(f"  é›¶å‡è®¾æ–¹æ³•: {detection_result.get('null_method', 'unknown')}")
    lines.append(f"  å¹¶è¡Œåç«¯: {detection_result.get('backend', 'sequential')}")
    
    if verbose:
        lines.append(f"  æ ·æœ¬æ•°: {detection_result.get('n_samples', 0)}")
        lines.append(f"  ç±»åˆ«æ•°: {detection_result.get('n_classes', 0)}")
        lines.append(f"  æ˜¯å¦åˆ†å±‚: {detection_result.get('stratified', False)}")
        lines.append(f"  æ˜¯å¦å­é‡‡æ ·: {detection_result.get('subsampled', False)}")
    
    return "\n".join(lines)


def create_risk_report(
    detection_result: Dict,
    metric_name: str = "performance",
    include_technical: bool = True,
    include_recommendations: bool = True
) -> str:
    """Create a comprehensive risk report combining summary and details.
    
    Parameters:
    -----------
    detection_result : dict
        Detection result
    metric_name : str
        Metric name
    include_technical : bool, default=True
        Include technical details
    include_recommendations : bool, default=True
        Include recommendations
    
    Returns:
    --------
    str
        Full risk report
    
    Examples:
    ---------
    >>> result = detect_bias(model, X, y, accuracy_score)
    >>> report = create_risk_report(result, "accuracy")
    >>> print(report)
    """
    sections = []
    
    # Main summary
    summary = generate_risk_summary(
        detection_result,
        metric_name,
        include_recommendations=include_recommendations
    )
    sections.append(f"## é£é™©è¯„ä¼°\n{summary}\n")
    
    # Technical details
    if include_technical:
        technical = format_technical_details(detection_result, verbose=True)
        sections.append(f"\n{technical}\n")
    
    # Conclusion
    p_value = detection_result.get('p_value', 1.0)
    alpha = detection_result.get('alpha', 0.05)
    
    if p_value <= alpha:
        sections.append(
            f"\nâš ï¸ **ç»“è®º**: æ£€æµ‹åˆ°ç»Ÿè®¡å­¦æ˜¾è‘—çš„å¼‚å¸¸æ¨¡å¼ï¼Œ"
            f"å»ºè®®è¿›è¡Œè¿›ä¸€æ­¥è°ƒæŸ¥ä»¥æ’é™¤ä½œå¼Šå¯èƒ½æ€§ã€‚"
        )
    else:
        sections.append(
            f"\nâœ… **ç»“è®º**: æœªæ£€æµ‹åˆ°æ˜æ˜¾çš„å¼‚å¸¸æ¨¡å¼ï¼Œ"
            f"ä½†ä»å»ºè®®ä¿æŒè­¦æƒ•å¹¶å®šæœŸç›‘æ§ã€‚"
        )
    
    return "\n".join(sections)
