"""
æ¡ˆä¾‹ç ”ç©¶å¯è§†åŒ–ç”Ÿæˆå™¨ - "æ±¡æŸ“å±æœº" (Contamination Crisis)

æœ¬è„šæœ¬ç”Ÿæˆæ¡ˆä¾‹ç ”ç©¶ä¸­ä½¿ç”¨çš„æ‰€æœ‰å›¾è¡¨å’Œå¯è§†åŒ–ï¼ŒåŒ…æ‹¬ï¼š
1. åå·®åˆ†æ•°åˆ†å¸ƒå›¾ (The Risk Map)
2. æ€§èƒ½ä¿®æ­£å¯¹æ¯”å›¾ (The Reality Check)
3. æ³„éœ²ç±»å‹åˆ†å¸ƒé¥¼å›¾
4. æ ·æœ¬çº§åˆ«çƒ­åŠ›å›¾

ä½œè€…: Hongping Zhang
æ—¥æœŸ: 2024-10-27
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Tuple
import os

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒï¼ˆå¦‚æœéœ€è¦ï¼‰
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# è®¾ç½®ç»˜å›¾é£æ ¼
sns.set_style("whitegrid")
plt.rcParams['figure.dpi'] = 300


class CaseStudyVisualizer:
    """æ¡ˆä¾‹ç ”ç©¶å¯è§†åŒ–ç”Ÿæˆå™¨"""
    
    def __init__(self, output_dir: str = "./case_study_figures"):
        """
        åˆå§‹åŒ–å¯è§†åŒ–å™¨
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
        """
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        print(f"âœ“ è¾“å‡ºç›®å½•: {output_dir}")
    
    def generate_contamination_risk_map(
        self,
        c_scores: np.ndarray,
        save_path: str = "contamination_risk_map.png"
    ):
        """
        ç”Ÿæˆåå·®åˆ†æ•°åˆ†å¸ƒå›¾ (The Risk Map)
        
        Args:
            c_scores: Circular Score æ•°ç»„
            save_path: ä¿å­˜è·¯å¾„
        """
        print("\nç”Ÿæˆå›¾è¡¨ 1: åå·®åˆ†æ•°åˆ†å¸ƒå›¾...")
        
        fig, ax = plt.subplots(figsize=(14, 7))
        
        # ç»˜åˆ¶ç›´æ–¹å›¾
        n, bins, patches = ax.hist(
            c_scores, 
            bins=50, 
            alpha=0.8, 
            color='steelblue', 
            edgecolor='black',
            linewidth=0.5
        )
        
        # æ·»åŠ é£é™©åŒºåŸŸèƒŒæ™¯è‰²
        ax.axvspan(0.00, 0.30, alpha=0.15, color='green', label='ğŸŸ¢ Low Risk (< 0.30)')
        ax.axvspan(0.30, 0.50, alpha=0.15, color='orange', label='ğŸŸ  Medium Risk (0.30-0.50)')
        ax.axvspan(0.50, 0.75, alpha=0.15, color='gold', label='ğŸŸ¡ High Risk (0.50-0.75)')
        ax.axvspan(0.75, 1.00, alpha=0.25, color='red', label='ğŸ”´ CRITICAL (â‰¥ 0.75)')
        
        # æ·»åŠ é˜ˆå€¼çº¿
        ax.axvline(x=0.30, color='orange', linestyle='--', linewidth=2, alpha=0.7)
        ax.axvline(x=0.50, color='gold', linestyle='--', linewidth=2, alpha=0.7)
        ax.axvline(x=0.75, color='red', linestyle='--', linewidth=2.5, alpha=0.8)
        
        # è®¾ç½®åæ ‡è½´
        ax.set_xlabel('Circular Score ($C_{score}$)', fontsize=16, fontweight='bold')
        ax.set_ylabel('Number of Samples', fontsize=16, fontweight='bold')
        ax.set_title(
            'Contamination Risk Distribution\nOpenDomainQA-2024 Evaluation Dataset',
            fontsize=18, 
            fontweight='bold',
            pad=20
        )
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯æ–‡æœ¬æ¡†
        stats_text = (
            f"Total Samples: {len(c_scores):,}\n"
            f"Critical (â‰¥0.75): {np.sum(c_scores >= 0.75):,} ({np.sum(c_scores >= 0.75)/len(c_scores)*100:.1f}%)\n"
            f"High (â‰¥0.50): {np.sum(c_scores >= 0.50):,} ({np.sum(c_scores >= 0.50)/len(c_scores)*100:.1f}%)\n"
            f"Medium (â‰¥0.30): {np.sum(c_scores >= 0.30):,} ({np.sum(c_scores >= 0.30)/len(c_scores)*100:.1f}%)\n"
            f"Mean: {np.mean(c_scores):.3f} | Median: {np.median(c_scores):.3f}"
        )
        ax.text(
            0.97, 0.97, stats_text,
            transform=ax.transAxes,
            fontsize=11,
            verticalalignment='top',
            horizontalalignment='right',
            bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor='gray', linewidth=1.5)
        )
        
        # å›¾ä¾‹
        ax.legend(loc='upper left', fontsize=11, frameon=True, shadow=True)
        
        # ç½‘æ ¼
        ax.grid(axis='y', alpha=0.3, linestyle=':', linewidth=0.8)
        ax.set_axisbelow(True)
        
        plt.tight_layout()
        full_path = os.path.join(self.output_dir, save_path)
        plt.savefig(full_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ“ å·²ä¿å­˜: {full_path}")
    
    def generate_performance_reality_check(
        self,
        original_acc: float = 95.1,
        corrected_acc: float = 58.3,
        save_path: str = "performance_reality_check.png"
    ):
        """
        ç”Ÿæˆæ€§èƒ½ä¿®æ­£å¯¹æ¯”å›¾ (The Reality Check)
        
        Args:
            original_acc: åŸå§‹å‡†ç¡®ç‡ (%)
            corrected_acc: ä¿®æ­£åå‡†ç¡®ç‡ (%)
            save_path: ä¿å­˜è·¯å¾„
        """
        print("\nç”Ÿæˆå›¾è¡¨ 2: æ€§èƒ½ä¿®æ­£å¯¹æ¯”å›¾...")
        
        fig, ax = plt.subplots(figsize=(11, 8))
        
        categories = ['Original\n(All Samples)\nn=10,000', 'Corrected\n(Clean Samples)\nn=6,000']
        accuracies = [original_acc, corrected_acc]
        colors = ['#3498DB', '#E74C3C']  # è“è‰²å’Œçº¢è‰²
        
        # ç»˜åˆ¶æŸ±çŠ¶å›¾
        bars = ax.bar(
            categories, 
            accuracies, 
            color=colors, 
            width=0.55,
            edgecolor='black', 
            linewidth=2.5,
            alpha=0.85
        )
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, acc in zip(bars, accuracies):
            height = bar.get_height()
            ax.text(
                bar.get_x() + bar.get_width()/2., 
                height + 1.5,
                f'{acc:.1f}%',
                ha='center', 
                va='bottom',
                fontsize=22, 
                fontweight='bold',
                color=bar.get_facecolor()
            )
        
        # æ·»åŠ ä¸‹é™ç®­å¤´
        arrow_start_x = 0
        arrow_end_x = 1
        arrow_start_y = original_acc - 2
        arrow_end_y = corrected_acc + 2
        
        ax.annotate(
            '',
            xy=(arrow_end_x, arrow_end_y),
            xytext=(arrow_start_x, arrow_start_y),
            arrowprops=dict(
                arrowstyle='->', 
                lw=4, 
                color='darkred',
                shrinkA=0,
                shrinkB=0
            )
        )
        
        # ä¸‹é™å¹…åº¦æ ‡æ³¨
        drop_percent = original_acc - corrected_acc
        ax.text(
            0.5, (original_acc + corrected_acc) / 2,
            f'-{drop_percent:.1f}%\nâ†“',
            ha='center',
            va='center',
            fontsize=20,
            fontweight='bold',
            color='darkred',
            bbox=dict(
                boxstyle='round,pad=0.5',
                facecolor='white',
                edgecolor='darkred',
                linewidth=3
            )
        )
        
        # è®¾ç½®åæ ‡è½´
        ax.set_ylabel('Accuracy (%)', fontsize=18, fontweight='bold')
        ax.set_title(
            'The Contamination Crisis:\nPerformance Before and After CBD Correction',
            fontsize=20,
            fontweight='bold',
            pad=25
        )
        ax.set_ylim(0, 110)
        ax.set_xlim(-0.7, 1.7)
        
        # æ·»åŠ å‚è€ƒçº¿
        ax.axhline(y=50, color='gray', linestyle=':', linewidth=1.5, alpha=0.5, label='50% Baseline')
        ax.axhline(y=75, color='gray', linestyle=':', linewidth=1.5, alpha=0.5, label='75% Target')
        
        # ç½‘æ ¼
        ax.grid(axis='y', alpha=0.3, linestyle='--', linewidth=0.8)
        ax.set_axisbelow(True)
        
        # æ·»åŠ è¯´æ˜æ–‡æœ¬
        impact_text = (
            "Impact: 36.8% performance drop\n"
            "when contaminated samples removed\n\n"
            "CBD reveals the true model capability"
        )
        ax.text(
            0.98, 0.05, impact_text,
            transform=ax.transAxes,
            fontsize=11,
            verticalalignment='bottom',
            horizontalalignment='right',
            style='italic',
            bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8, edgecolor='orange', linewidth=2)
        )
        
        plt.tight_layout()
        full_path = os.path.join(self.output_dir, save_path)
        plt.savefig(full_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ“ å·²ä¿å­˜: {full_path}")
    
    def generate_leakage_type_distribution(
        self,
        leakage_types: Dict[str, int],
        save_path: str = "leakage_type_distribution.png"
    ):
        """
        ç”Ÿæˆæ³„éœ²ç±»å‹åˆ†å¸ƒé¥¼å›¾
        
        Args:
            leakage_types: æ³„éœ²ç±»å‹å­—å…¸ {ç±»å‹: æ•°é‡}
            save_path: ä¿å­˜è·¯å¾„
        """
        print("\nç”Ÿæˆå›¾è¡¨ 3: æ³„éœ²ç±»å‹åˆ†å¸ƒå›¾...")
        
        fig, ax = plt.subplots(figsize=(11, 8))
        
        labels = list(leakage_types.keys())
        sizes = list(leakage_types.values())
        colors = ['#FF6B6B', '#4ECDC4', '#FFD93D', '#95E1D3']
        explode = (0.05, 0.05, 0.05, 0.05)
        
        # ç»˜åˆ¶é¥¼å›¾
        wedges, texts, autotexts = ax.pie(
            sizes,
            labels=labels,
            autopct='%1.1f%%',
            startangle=90,
            colors=colors,
            explode=explode,
            shadow=True,
            textprops={'fontsize': 13, 'fontweight': 'bold'}
        )
        
        # ç¾åŒ–ç™¾åˆ†æ¯”æ–‡æœ¬
        for autotext in autotexts:
            autotext.set_color('white')
            autotext.set_fontsize(14)
            autotext.set_fontweight('bold')
        
        ax.set_title(
            'Distribution of Leakage Types\n(Among Contaminated Samples)',
            fontsize=18,
            fontweight='bold',
            pad=20
        )
        
        # æ·»åŠ å›¾ä¾‹
        legend_labels = [
            f"{label}: {size:,} samples" 
            for label, size in zip(labels, sizes)
        ]
        ax.legend(
            legend_labels,
            loc='center left',
            bbox_to_anchor=(1, 0, 0.5, 1),
            fontsize=11,
            frameon=True,
            shadow=True
        )
        
        plt.tight_layout()
        full_path = os.path.join(self.output_dir, save_path)
        plt.savefig(full_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ“ å·²ä¿å­˜: {full_path}")
    
    def generate_sample_heatmap(
        self,
        c_scores_matrix: np.ndarray,
        sample_ids: List[int],
        train_ids: List[int],
        save_path: str = "sample_contamination_heatmap.png"
    ):
        """
        ç”Ÿæˆæ ·æœ¬çº§åˆ«æ±¡æŸ“çƒ­åŠ›å›¾
        
        Args:
            c_scores_matrix: C_score çŸ©é˜µ (eval_samples x train_samples)
            sample_ids: è¯„ä¼°æ ·æœ¬IDåˆ—è¡¨
            train_ids: è®­ç»ƒæ ·æœ¬IDåˆ—è¡¨
            save_path: ä¿å­˜è·¯å¾„
        """
        print("\nç”Ÿæˆå›¾è¡¨ 4: æ ·æœ¬æ±¡æŸ“çƒ­åŠ›å›¾...")
        
        fig, ax = plt.subplots(figsize=(14, 10))
        
        # ç»˜åˆ¶çƒ­åŠ›å›¾
        im = ax.imshow(
            c_scores_matrix,
            cmap='YlOrRd',
            aspect='auto',
            interpolation='nearest',
            vmin=0,
            vmax=1
        )
        
        # æ·»åŠ é¢œè‰²æ¡
        cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
        cbar.set_label('Circular Score ($C_{score}$)', fontsize=14, fontweight='bold')
        
        # è®¾ç½®åæ ‡è½´æ ‡ç­¾
        ax.set_xlabel('Training Sample Index', fontsize=14, fontweight='bold')
        ax.set_ylabel('Evaluation Sample Index', fontsize=14, fontweight='bold')
        ax.set_title(
            'Sample-Level Contamination Heatmap\n(Top 50 Eval Samples Ã— Top 50 Train Samples)',
            fontsize=16,
            fontweight='bold',
            pad=20
        )
        
        # ç®€åŒ–åˆ»åº¦ï¼ˆåªæ˜¾ç¤ºéƒ¨åˆ†ï¼‰
        if len(sample_ids) > 10:
            step = len(sample_ids) // 10
            ax.set_yticks(range(0, len(sample_ids), step))
            ax.set_yticklabels([sample_ids[i] for i in range(0, len(sample_ids), step)])
        
        if len(train_ids) > 10:
            step = len(train_ids) // 10
            ax.set_xticks(range(0, len(train_ids), step))
            ax.set_xticklabels([train_ids[i] for i in range(0, len(train_ids), step)])
        
        plt.tight_layout()
        full_path = os.path.join(self.output_dir, save_path)
        plt.savefig(full_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ“ å·²ä¿å­˜: {full_path}")


def generate_synthetic_data(n_samples: int = 10000, seed: int = 42) -> pd.DataFrame:
    """
    ç”Ÿæˆæ¨¡æ‹Ÿçš„æ¡ˆä¾‹ç ”ç©¶æ•°æ®
    
    Args:
        n_samples: æ ·æœ¬æ•°é‡
        seed: éšæœºç§å­
        
    Returns:
        åŒ…å« C_score çš„ DataFrame
    """
    np.random.seed(seed)
    
    # æ¨¡æ‹Ÿä¸åŒé£é™©ç­‰çº§çš„æ ·æœ¬
    n_low = int(n_samples * 0.60)  # 60% ä½é£é™©
    n_medium = int(n_samples * 0.25)  # 25% ä¸­ç­‰é£é™©
    n_high = int(n_samples * 0.12)  # 12% é«˜é£é™©
    n_critical = n_samples - n_low - n_medium - n_high  # 3% å…³é”®é£é™©
    
    # ä¸ºæ¯ä¸ªé£é™©ç­‰çº§ç”Ÿæˆ C_score
    c_scores_low = np.random.beta(2, 8, n_low) * 0.30  # é›†ä¸­åœ¨ 0-0.30
    c_scores_medium = np.random.beta(3, 3, n_medium) * 0.20 + 0.30  # é›†ä¸­åœ¨ 0.30-0.50
    c_scores_high = np.random.beta(3, 2, n_high) * 0.25 + 0.50  # é›†ä¸­åœ¨ 0.50-0.75
    c_scores_critical = np.random.beta(2, 1, n_critical) * 0.25 + 0.75  # é›†ä¸­åœ¨ 0.75-1.0
    
    # åˆå¹¶æ‰€æœ‰åˆ†æ•°
    all_c_scores = np.concatenate([
        c_scores_low,
        c_scores_medium,
        c_scores_high,
        c_scores_critical
    ])
    
    # éšæœºæ‰“ä¹±
    np.random.shuffle(all_c_scores)
    
    # åˆ›å»º DataFrame
    df = pd.DataFrame({
        'sample_id': range(n_samples),
        'c_score': all_c_scores,
        'risk_level': ['ğŸŸ¢ Low' if s < 0.30 else 
                       'ğŸŸ  Medium' if s < 0.50 else 
                       'ğŸŸ¡ High' if s < 0.75 else 
                       'ğŸ”´ Critical' for s in all_c_scores]
    })
    
    return df


def main():
    """ä¸»å‡½æ•°ï¼šç”Ÿæˆæ‰€æœ‰æ¡ˆä¾‹ç ”ç©¶å¯è§†åŒ–"""
    
    print("=" * 70)
    print("æ¡ˆä¾‹ç ”ç©¶å¯è§†åŒ–ç”Ÿæˆå™¨ - æ±¡æŸ“å±æœº")
    print("=" * 70)
    
    # åˆå§‹åŒ–å¯è§†åŒ–å™¨
    visualizer = CaseStudyVisualizer(output_dir="./case_study_figures")
    
    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    print("\næ­¥éª¤ 1: ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®...")
    df_contamination = generate_synthetic_data(n_samples=10000, seed=42)
    print(f"âœ“ ç”Ÿæˆäº† {len(df_contamination)} ä¸ªæ ·æœ¬")
    print(f"\né£é™©åˆ†å¸ƒ:")
    print(df_contamination['risk_level'].value_counts().sort_index())
    
    # ä¿å­˜æ•°æ®
    data_path = os.path.join(visualizer.output_dir, "contamination_data.csv")
    df_contamination.to_csv(data_path, index=False)
    print(f"âœ“ æ•°æ®å·²ä¿å­˜åˆ°: {data_path}")
    
    # å›¾è¡¨ 1: åå·®åˆ†æ•°åˆ†å¸ƒå›¾
    print("\n" + "=" * 70)
    visualizer.generate_contamination_risk_map(
        c_scores=df_contamination['c_score'].values,
        save_path="contamination_risk_map.png"
    )
    
    # å›¾è¡¨ 2: æ€§èƒ½ä¿®æ­£å¯¹æ¯”å›¾
    print("\n" + "=" * 70)
    visualizer.generate_performance_reality_check(
        original_acc=95.1,
        corrected_acc=58.3,
        save_path="performance_reality_check.png"
    )
    
    # å›¾è¡¨ 3: æ³„éœ²ç±»å‹åˆ†å¸ƒ
    print("\n" + "=" * 70)
    leakage_types = {
        'Exact Match': 120,
        'Paraphrase': 850,
        'Partial Overlap': 1530,
        'Semantic Similar': 1500
    }
    visualizer.generate_leakage_type_distribution(
        leakage_types=leakage_types,
        save_path="leakage_type_distribution.png"
    )
    
    # å›¾è¡¨ 4: æ ·æœ¬çƒ­åŠ›å›¾
    print("\n" + "=" * 70)
    # ç”Ÿæˆæ¨¡æ‹Ÿçš„ C_score çŸ©é˜µï¼ˆ50 x 50ï¼‰
    n_eval = 50
    n_train = 50
    c_scores_matrix = np.random.beta(2, 5, (n_eval, n_train))
    # æ·»åŠ ä¸€äº›é«˜é£é™©æ ·æœ¬
    c_scores_matrix[5:10, 10:15] = np.random.uniform(0.7, 0.9, (5, 5))
    c_scores_matrix[20:25, 30:35] = np.random.uniform(0.75, 0.95, (5, 5))
    
    visualizer.generate_sample_heatmap(
        c_scores_matrix=c_scores_matrix,
        sample_ids=list(range(n_eval)),
        train_ids=list(range(n_train)),
        save_path="sample_contamination_heatmap.png"
    )
    
    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    print("\n" + "=" * 70)
    print("å¯è§†åŒ–ç”Ÿæˆå®Œæˆ!")
    print("=" * 70)
    print(f"\nç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"  1. contamination_risk_map.png - åå·®åˆ†æ•°åˆ†å¸ƒå›¾")
    print(f"  2. performance_reality_check.png - æ€§èƒ½ä¿®æ­£å¯¹æ¯”å›¾")
    print(f"  3. leakage_type_distribution.png - æ³„éœ²ç±»å‹åˆ†å¸ƒå›¾")
    print(f"  4. sample_contamination_heatmap.png - æ ·æœ¬æ±¡æŸ“çƒ­åŠ›å›¾")
    print(f"  5. contamination_data.csv - æ¨¡æ‹Ÿæ•°æ®")
    print(f"\næ‰€æœ‰æ–‡ä»¶å·²ä¿å­˜åˆ°: {visualizer.output_dir}")
    print("\nâœ… å®Œæˆï¼")


if __name__ == "__main__":
    main()
